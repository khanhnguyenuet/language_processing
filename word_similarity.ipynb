{
 "cells": [
  {
   "source": [
    "# 1. Cosine similarity  \n",
    "Given pre-trained embeddings of Vietnamese words, implement a function for calculating cosine similarity between word pairs. Test your program using word pairs in ViSim-400 dataset (in directory Datasets/ViSim-400). Using Pearson correlation coefficient (https://en.wikipedia.org/wiki/Pearson_correlation_coefficient), Spearman's rank correlation coefficient (https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient) to evaluate the correlation between your results and similarity scores in the dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_to_list(path):\n",
    "    file = open(path)\n",
    "    lines = [line for line in file.readlines()]\n",
    "    file.close()\n",
    "    return lines"
   ]
  },
  {
   "source": [
    "w2v_path = 'W2V_150.txt'\n",
    "dataset = read_file_to_list(w2v_path)\n",
    "\n",
    "num_of_words = int(dataset[0]) #77021 từ trong bộ embedding \n",
    "num_of_dimensions = int(dataset[1]) # mỗi từ tương ứng với 1 véctơ 150 chiều \n",
    "dataset = dataset[2:]\n",
    "\n",
    "vector = [None]*num_of_dimensions\n",
    "embeddings = {}\n",
    "\n",
    "for line in dataset:\n",
    "    s = line.split(' ')\n",
    "    word = s[0]\n",
    "    for i in range(num_of_dimensions):\n",
    "        vector[i] = float(s[i+2]) # trừ item đầu tiên và thứ 2 (xâu rỗng)\n",
    "    embeddings[word] = np.array(vector)\n",
    "# dict(list(embeddings.items())[0:2])"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "source": [
    "implement a function for calculating cosine similarity between word pairs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T09:57:00.830303Z",
     "iopub.status.busy": "2020-11-13T09:57:00.829458Z",
     "iopub.status.idle": "2020-11-13T09:57:00.832657Z",
     "shell.execute_reply": "2020-11-13T09:57:00.831838Z"
    },
    "papermill": {
     "duration": 0.034753,
     "end_time": "2020-11-13T09:57:00.832826",
     "exception": false,
     "start_time": "2020-11-13T09:57:00.798073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(A, B):\n",
    "   return np.sum(A*B) / np.sqrt(np.sum(A**2)*np.sum(B**2))"
   ]
  },
  {
   "source": [
    "chuẩn hóa kết quả về \\[0, 1\\]"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.48198830650084357"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "(1 + cosine_similarity(embeddings['wallpaper'], embeddings['sâu']) ) / 2"
   ]
  },
  {
   "source": [
    "Test your program using word pairs in ViSim-400 dataset  \n",
    "Results stored in *rs*"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.497543830265165,\n",
       " 0.5412615916460588,\n",
       " 0.6385429799341388,\n",
       " 0.5883993141781336,\n",
       " 0.4706390934550245]"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "visim_path = \"Visim-400.txt\"\n",
    "lines = read_file_to_list(visim_path)[1:]\n",
    "\n",
    "results = []\n",
    "\n",
    "for line in lines:\n",
    "    s = line.split()\n",
    "    w1 = s[0].strip() #word 1\n",
    "    if w1 not in embeddings:\n",
    "        embeddings[w1] = np.ones(num_of_dimensions)\n",
    "    w2 = s[1].strip() #word 2\n",
    "    if w2 not in embeddings:\n",
    "        embeddings[w2] = np.ones(num_of_dimensions)\n",
    "    sim = (1+cosine_similarity(embeddings[w1], embeddings[w2]))/2\n",
    "    results.append(sim)\n",
    "\n",
    "results[:5]"
   ]
  },
  {
   "source": [
    "## Evaluate the correlation between the results and similarity scores in the dataset  \n",
    "### similarity scores in dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [line.split() for line in lines]\n",
    "scores = np.array(l)[:,3].astype(np.float)"
   ]
  },
  {
   "source": [
    "Using Pearson correlation coefficient"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.3787184443819735, 4.337055364178592e-15)"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "stats.pearsonr(results, scores)"
   ]
  },
  {
   "source": [
    "Using Spearman correlation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.3286625921444831, pvalue=1.5746522506040425e-11)"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "stats.spearmanr(results, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.9437165488107271, 0.015892932682276078)"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "l1 = [1,2,3,4,5]\n",
    "l2 = [2.5,3,5,10,16]\n",
    "stats.pearsonr(l1,l2)"
   ]
  },
  {
   "source": [
    "# 2. K-nearest words  \n",
    "Given a word w, find k most-similar words of w using the function implemented in 1."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([  212,  2384, 55449,  1519])"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "def knearest_words(k, word):\n",
    "    rs = []\n",
    "    d = {}\n",
    "    for w in embeddings:\n",
    "        sim = (1+cosine_similarity(embeddings[word], embeddings[w])) / 2\n",
    "        rs.append(sim)\n",
    "    rs = np.array(rs)\n",
    "    ind = np.argpartition(rs, -4)[-4:]\n",
    "    return ind\n",
    "knearest_words(10, 'xinh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "word_to_index = {}\n",
    "i = 0\n",
    "for w in embeddings.keys():\n",
    "    word_to_index[w] = i\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(word_to_index.keys())\n",
    "index_to_word = dict(zip(word_to_index.values(), word_to_index.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "77072"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "len(index_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(77021, 77021)"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "# similarity_table = np.zeros((num_of_words, num_of_words), dtype=np.int8)\n",
    "# similarity_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "papermill": {
   "duration": 77.882864,
   "end_time": "2020-11-13T09:57:01.832938",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-13T09:55:43.950074",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}