{
 "cells": [
  {
   "source": [
    "# 1. Cosine similarity  \n",
    "Given pre-trained embeddings of Vietnamese  words, implement a function for calculating cosine similarity between word pairs. Test your program using word pairs in ViSim-400 dataset (in directory Datasets/ViSim-400). Using Pearson correlation coefficient (https://en.wikipedia.org/wiki/Pearson_correlation_coefficient), Spearman's rank correlation coefficient (https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient) to evaluate the correlation between your results and similarity scores in the dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_to_list(path):\n",
    "    file = open(path, encoding='utf8')\n",
    "    lines = [line for line in file.readlines()]\n",
    "    file.close()\n",
    "    return lines"
   ]
  },
  {
   "source": [
    "w2v_path = 'W2V_150.txt'\n",
    "dataset = read_file_to_list(w2v_path)\n",
    "\n",
    "num_of_words = int(dataset[0]) #77021 từ trong bộ embedding \n",
    "num_of_dimensions = int(dataset[1]) # mỗi từ tương ứng với 1 véctơ 150 chiều \n",
    "dataset = dataset[2:]\n",
    "\n",
    "vector = [None]*num_of_dimensions\n",
    "embeddings = {}\n",
    "\n",
    "for line in dataset:\n",
    "    s = line.split(' ')\n",
    "    word = s[0]\n",
    "    for i in range(num_of_dimensions):\n",
    "        vector[i] = float(s[i+2]) # trừ item đầu tiên và thứ 2 (xâu rỗng)\n",
    "    embeddings[word] = np.array(vector)\n",
    "# dict(list(embeddings.items())[0:2])"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "source": [
    "implement a function for calculating cosine similarity between word pairs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T09:57:00.830303Z",
     "iopub.status.busy": "2020-11-13T09:57:00.829458Z",
     "iopub.status.idle": "2020-11-13T09:57:00.832657Z",
     "shell.execute_reply": "2020-11-13T09:57:00.831838Z"
    },
    "papermill": {
     "duration": 0.034753,
     "end_time": "2020-11-13T09:57:00.832826",
     "exception": false,
     "start_time": "2020-11-13T09:57:00.798073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(A, B):\n",
    "   return np.sum(A*B) / np.sqrt(np.sum(A**2)*np.sum(B**2))"
   ]
  },
  {
   "source": [
    "chuẩn hóa kết quả về thang \\[0, 10\\]"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "7.420035500261395"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "(1 + cosine_similarity(embeddings['cute'], embeddings['xinh_xắn']) ) / 2 * 10"
   ]
  },
  {
   "source": [
    "Test your program using word pairs in ViSim-400 dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_floats(start, end, size):\n",
    "    mid = start + (end-start)/2\n",
    "    x = mid + np.random.rand(size) * (end-mid)\n",
    "    sign = np.random.rand(size)\n",
    "    sign[sign < 0.5] = -1\n",
    "    sign[sign != -1] = 1\n",
    "    x = x*sign\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "visim_path = \"Visim-400.txt\"\n",
    "lines = read_file_to_list(visim_path)[1:]\n",
    "\n",
    "results = []\n",
    "\n",
    "for line in lines:\n",
    "    s = line.split()\n",
    "    w1 = s[0].strip() #word 1\n",
    "\n",
    "    # những từ không có trong bộ pretrained embedding sẽ được khởi tạo ngẫu nhiên\n",
    "    if w1 not in embeddings:\n",
    "        embeddings[w1] = generate_floats(-2, 2, num_of_dimensions) # gán giá trị float ngẫu nhiên trong khoảng [-2,2)\n",
    "        \n",
    "    w2 = s[1].strip() #word 2\n",
    "    if w2 not in embeddings:\n",
    "        embeddings[w2] = generate_floats(-2, 2, num_of_dimensions)\n",
    "    sim = (1+cosine_similarity(embeddings[w1], embeddings[w2]))/2*10\n",
    "    results.append(sim)\n",
    "\n",
    "# results[:5]"
   ]
  },
  {
   "source": [
    "## Evaluate the correlation between the results and similarity scores in the dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [line.split() for line in lines]\n",
    "scores = np.array(l)[:,4].astype(np.float) #lấy dữ liệu từ cột 4 (Sim2) (thang 0-10)"
   ]
  },
  {
   "source": [
    "Using Pearson correlation coefficient"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.3357354165588622, 5.39275709671148e-12)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "stats.pearsonr(results, scores)"
   ]
  },
  {
   "source": [
    "Using Spearman correlation coefficient"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.29379062171006726, pvalue=2.0968429623116215e-09)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "stats.spearmanr(results, scores)"
   ]
  },
  {
   "source": [
    "# 2. K-nearest words  \n",
    "Given a word w, find k most-similar words of w using the function implemented in 1."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['những',\n",
       " 'tiết_lộ',\n",
       " 'thú_vị',\n",
       " 'về',\n",
       " 'wallpaper',\n",
       " 'mặc_định',\n",
       " 'của',\n",
       " 'windows',\n",
       " 'xp',\n",
       " 'chắc_hẳn']"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "vocab = list(embeddings.keys())\n",
    "vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(embeddings.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(\n",
    "    n_clusters=20,\n",
    "    n_init=10, max_iter=100,\n",
    "    tol=1e-04, random_state=0\n",
    ")\n",
    "clustering = kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knearest_words(k, w):\n",
    "    rs = []\n",
    "    label = clustering.predict(embeddings[w].reshape((1,150)))\n",
    "\n",
    "    for i in range(num_of_words):\n",
    "        if labels[i] == label.item():\n",
    "            sim = cosine_similarity(embeddings[vocab[i]], embeddings[w])\n",
    "            rs.append(sim)\n",
    "        else:\n",
    "            rs.append(-1)\n",
    "            \n",
    "    rs = np.argsort(np.array(rs)) #trả các idx theo 1 thứ tự mà mảng sẽ được sx nếu duyệt theo thứ tự đó\n",
    "    return rs[-2:-k-2:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['đẹp',\n",
       " 'dễ_thương',\n",
       " 'đáng_yêu',\n",
       " 'kute',\n",
       " 'tôn_dáng',\n",
       " 'đỏm_dáng',\n",
       " 'nuột',\n",
       " 'oách',\n",
       " 'manly',\n",
       " 'dừ']"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "kq = [vocab[i] for i in knearest_words(10, 'xinh')]\n",
    "kq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "papermill": {
   "duration": 77.882864,
   "end_time": "2020-11-13T09:57:01.832938",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-13T09:55:43.950074",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
