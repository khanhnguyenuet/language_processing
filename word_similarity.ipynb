{
 "cells": [
  {
   "source": [
    "# 1. Cosine similarity  \n",
    "Given pre-trained embeddings of Vietnamese words, implement a function for calculating cosine similarity between word pairs. Test your program using word pairs in ViSim-400 dataset (in directory Datasets/ViSim-400). Using Pearson correlation coefficient (https://en.wikipedia.org/wiki/Pearson_correlation_coefficient), Spearman's rank correlation coefficient (https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient) to evaluate the correlation between your results and similarity scores in the dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_to_list(path):\n",
    "    file = open(path)\n",
    "    lines = [line for line in file.readlines()]\n",
    "    file.close()\n",
    "    return lines"
   ]
  },
  {
   "source": [
    "w2v_path = 'W2V_150.txt'\n",
    "dataset = read_file_to_list(w2v_path)\n",
    "\n",
    "num_of_words = int(dataset[0]) #77021 từ trong bộ embedding \n",
    "num_of_dimensions = int(dataset[1]) # mỗi từ tương ứng với 1 véctơ 150 chiều \n",
    "dataset = dataset[2:]\n",
    "\n",
    "vector = [None]*num_of_dimensions\n",
    "embeddings = {}\n",
    "\n",
    "for line in dataset:\n",
    "    s = line.split(' ')\n",
    "    word = s[0]\n",
    "    for i in range(num_of_dimensions):\n",
    "        vector[i] = float(s[i+2]) # trừ item đầu tiên và thứ 2 (xâu rỗng)\n",
    "    embeddings[word] = np.array(vector)\n",
    "# dict(list(embeddings.items())[0:2])"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "source": [
    "implement a function for calculating cosine similarity between word pairs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T09:57:00.830303Z",
     "iopub.status.busy": "2020-11-13T09:57:00.829458Z",
     "iopub.status.idle": "2020-11-13T09:57:00.832657Z",
     "shell.execute_reply": "2020-11-13T09:57:00.831838Z"
    },
    "papermill": {
     "duration": 0.034753,
     "end_time": "2020-11-13T09:57:00.832826",
     "exception": false,
     "start_time": "2020-11-13T09:57:00.798073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(A, B):\n",
    "   return np.sum(A*B) / np.sqrt(np.sum(A**2)*np.sum(B**2))"
   ]
  },
  {
   "source": [
    "chuẩn hóa kết quả về \\[0, 1\\]"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.48198830650084357"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "(1 + cosine_similarity(embeddings['wallpaper'], embeddings['sâu']) ) / 2"
   ]
  },
  {
   "source": [
    "Test your program using word pairs in ViSim-400 dataset  \n",
    "Results stored in *rs*"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.497543830265165,\n",
       " 0.5412615916460588,\n",
       " 0.6385429799341388,\n",
       " 0.5883993141781336,\n",
       " 0.4706390934550245]"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "visim_path = \"Visim-400.txt\"\n",
    "lines = read_file_to_list(visim_path)[1:]\n",
    "\n",
    "results = []\n",
    "\n",
    "for line in lines:\n",
    "    s = line.split()\n",
    "    w1 = s[0].strip() #word 1\n",
    "    if w1 not in embeddings:\n",
    "        embeddings[w1] = np.ones(num_of_dimensions)\n",
    "    w2 = s[1].strip() #word 2\n",
    "    if w2 not in embeddings:\n",
    "        embeddings[w2] = np.ones(num_of_dimensions)\n",
    "    sim = (1+cosine_similarity(embeddings[w1], embeddings[w2]))/2\n",
    "    results.append(sim)\n",
    "\n",
    "results[:5]"
   ]
  },
  {
   "source": [
    "## Evaluate the correlation between the results and similarity scores in the dataset  \n",
    "### similarity scores in dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [line.split() for line in lines]\n",
    "scores = np.array(l)[:,3].astype(np.float) #lấy dữ liệu từ cột 3 (Sim1) và chuyển về dạng float"
   ]
  },
  {
   "source": [
    "Using Pearson correlation coefficient"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.3787184443819735, 4.337055364178592e-15)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "stats.pearsonr(results, scores)"
   ]
  },
  {
   "source": [
    "Using Spearman correlation coefficient"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.3286625921444831, pvalue=1.5746522506040425e-11)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "stats.spearmanr(results, scores)"
   ]
  },
  {
   "source": [
    "### sao hệ số tương quan lại thấp thể nhể???"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.9437165488107271, 0.015892932682276078)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "l1 = [1,2,3,4,5]\n",
    "l2 = [2.5,3,5,10,16]\n",
    "stats.pearsonr(l1,l2)"
   ]
  },
  {
   "source": [
    "# 2. K-nearest words  \n",
    "Given a word w, find k most-similar words of w using the function implemented in 1."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "hiện tại đang làm theo kiểu duyệt hết rồi tính cosine_similarity lần lượt, sau đó lấy ra k kết quả nhỏ nhất"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['những',\n",
       " 'tiết_lộ',\n",
       " 'thú_vị',\n",
       " 'về',\n",
       " 'wallpaper',\n",
       " 'mặc_định',\n",
       " 'của',\n",
       " 'windows',\n",
       " 'xp',\n",
       " 'chắc_hẳn']"
      ]
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "vocab = list(embeddings.keys())\n",
    "vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def knearest_words(k, word):\n",
    "    rs = []\n",
    "    d = {}\n",
    "    for w in vocab:\n",
    "        sim = (1+cosine_similarity(embeddings[word], embeddings[w])) / 2\n",
    "        rs.append(sim)\n",
    "    rs = np.argsort(np.array(rs)) #trả các idx theo 1 thứ tự mà mảng sẽ được sx nếu duyệt theo thứ tự đó\n",
    "    return rs[-2:-k-2:-1] #lấy ngược lại từ cuối, trừ vị trí cuối (chính là từ đang xét)"
   ]
  },
  {
   "source": [
    "ô dưới để minh họa cho argsort"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0, 2, 3, 1, 4, 8, 5, 6, 7])"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "a = [1,5,2,3,5,7,8,9,5]\n",
    "np.argsort(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['cute',\n",
       " 'xinh_xắn',\n",
       " 'đẹp',\n",
       " 'dễ_thương',\n",
       " 'đáng_yêu',\n",
       " 'kute',\n",
       " 'tôn_dáng',\n",
       " 'xinh_tươi',\n",
       " 'đỏm_dáng',\n",
       " 'xinh_đẹp']"
      ]
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "kq = [vocab[i] for i in knearest_words(10, 'xinh')]\n",
    "kq"
   ]
  },
  {
   "source": [
    "# 3. Synonym-antonym classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "papermill": {
   "duration": 77.882864,
   "end_time": "2020-11-13T09:57:01.832938",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-13T09:55:43.950074",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}